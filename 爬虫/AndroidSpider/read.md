2-3 基本爬取技术思路
爬虫涉及的通用技术最核心的可能就是 HTTP 请求了，我们至少至少应该掌握 HTTP 的 POST 和 GET 请求方法；其次就是 HTTP 请求和返回的 Header 含义及如何使用浏览器等工具跟踪请求 Header，因为爬虫链接请求时出现问题最多的情况一般都是 Header 有问题，譬如通常至少要保证 User-Agent、Referer、Cookie 等的伪装正确性，返回 Header 里的重定向链接，Gzip 数据需要解压等；还有就是 POST 数据的 urlencode 包装发送等；所以在进行爬虫前一定要具备比较扎实的前端与后端基础知识，同时要具备比较充足的 HTTP 知识。

有了这些知识我们可能就会急于开始爬取，其实这是不对的，我们应该做的第一件事是对要爬取的站点进行分析，至于如何分析，下面给出了一些常规套路：

首先倒腾下看你要抓取的站点有没有响应式的移动页面，如果有那就保持一个原则，尽可能的抓取他们的移动页面（原因就是一般移动页面都是内容干货啊，相对 PC 页面没那么臃肿，方便分析）。

Cookie 的操蛋之处，分析时建议开启隐身模式等，不然就面对清空 Cookie 大法了，清空 Cookie 对于爬虫网站分析至关重要，一定要 get 到。

分析爬取网页是静态页面还是动态页面，以便采取不同的爬取策略，使用不同的爬取工具。

查看网页源码找出对你有价值的数据的网页排版规律，譬如特定 CSS 选择等，从而指定抓取后的数据解析规则。

清洗数据后选择如何处理抓取到的有价值数据，譬如是存储还是直接使用，是如何存储等。